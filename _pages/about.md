---
layout: about
title: about
permalink: /
subtitle: [HammerLab](https://hammer-lab.techfak.uni-bielefeld.de/) at Bielefeld University. Shapley Enthusiast. [`shapiq`](https://shapiq.readthedocs.io/en/latest/#) Developer.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>CITEC </p>
    <p>Inspiration 1, D-33615 </p>
    <p>Bielefeld, Germany</p>

news: false # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page
---

Hi! I am Fabian Fumagalli, PhD Student in the Machine Learning group of Prof. Barbara Hammer ([HammerLab](https://hammer-lab.techfak.uni-bielefeld.de/)) at Bielefeld University.

# Research Focus
My current research focuses on eXplainable AI (XAI). Specifically, leveraging fundamental concepts of statistics, such a functional ANOVA, and game-theoretic concepts, such as the Shapley value. One main application are feature-based explanations, where my research focused on efficient computations of the Shapley value and its extension to higher-order interactions, Shapley interacitons. I am further interested in the computational challenges of these mathematical concepts, and the theoretical similarities, differences, and possible guarantees of feature-based explanations. Beyond feature-based explanations, I am interested in exploring novel applications of Shapley values and interactions to understand improve areas in machine learning, such as LLM promopt compisition or hyperparameter optimization.

I am an active developer of the [`shapiq`](https://shapiq.readthedocs.io/en/latest/#), which extends the popular `shap`package with any-order feature interactions. `shapiq` additionally separates the game-theoretic concepts and computations from the application on feature-based explanations, which allows to apply Shapley values and interactions on other machine learning applications, finding optimal LLM prompt composition or understanding hyperparameter optimization.

In previous work, I focused also on efficient computation of explanations in rapidly changing dynamic enviornments, such as data streams.

I am part of the interdisciplinary collaborative research centre [TRR 318 Constructing Explainability](https://trr318.uni-paderborn.de/en/)
