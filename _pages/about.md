---
layout: about
title: about
permalink: /
subtitle: PhD Student in the <a href='https://hammer-lab.techfak.uni-bielefeld.de/'> Machine Learning Group </a> at Bielefeld University. Shapley Enthusiast and <a href='https://shapiq.readthedocs.io/en/latest/#'>shapiq</a> Developer.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>CITEC, Inspiration 1 </p>
    <p>D-33615 Bielefeld, Germany</p>

news: false # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

---

## Research Focus
My current research focuses on eXplainable AI (XAI). Specifically, leveraging fundamental concepts of statistics, such a functional ANOVA, and game-theoretic concepts, such as the Shapley value, to understand and improve machine learning models and tasks. One main application are feature-based explanations, where I'm interested in efficient computations of the Shapley value and its extension to higher-order interactions. By using these concepts, I did research about the theoretical similarities, differences, and possible guarantees of feature-based explanations. Beyond feature-based explanations, I am interested in exploring novel applications of Shapley values and interactions to understand and improve other areas in machine learning, such as LLM prompt compositions or hyperparameter optimization.

I am an active developer of the [shapiq](https://shapiq.readthedocs.io/en/latest/#), which extends the popular [shap](https://shap.readthedocs.io/en/latest/) package to any-order feature interactions. [shapiq](https://shapiq.readthedocs.io/en/latest/#) additionally separates the game-theoretic concepts and computations from the application on feature-based explanations, which allows to apply Shapley values and interactions on other machine learning applications.

Another area of my research are explanations in rapidly changing dynamic environments, such as data streams.

I am funded by the interdisciplinary collaborative research centre [TRR 318 Constructing Explainability](https://trr318.uni-paderborn.de/en/).
