---
layout: about
title: about
permalink: /
subtitle: Interim Professor for Statistical Learning and Data Science at LMU Munich (winter term 2025/2026). Active developer of <a href='https://shapiq.readthedocs.io/en/latest/#'>shapiq</a>.

profile:
  align: right
  image: img.jpg
  image_circular: false # crops the image to make it circular
  more_info:
news: false # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

---

## Research Focus
My research focuses on eXplainable AI (XAI) and I am passionate about making machine learning models more transparent and trustworthy. By leveraging mathematical concepts such as [Shapley interactions](https://arxiv.org/abs/2410.01649), which address limitations of the [Shapley value](https://christophm.github.io/interpretable-ml-book/shapley.html), and [functional ANOVA](https://epubs.siam.org/doi/abs/10.1137/120876782), I aim to make model decisions more understandable to users. My goal is to narrow the gap between complex machine learning models and practical, interpretable solutions.

Beyond feature-based explanations, I am exploring novel [applications of the Shapley value](https://www.ijcai.org/proceedings/2022/0778) and interactions to enhance other areas in machine learning, such as large language model (LLM) prompt composition and hyperparameter optimization.

I actively contribute to the development of [`shapiq`](https://shapiq.readthedocs.io/en/latest/#), which extends the popular [`shap`](https://shap.readthedocs.io/en/latest/) package to support any-order feature interactions. [`shapiq`](https://shapiq.readthedocs.io/en/latest/#) decouples the computation of game-theoretic concepts from feature-based explanations, enabling the application of Shapley values and interactions across various machine learning tasks.

Another area of my research focuses on explanations in dynamic environments, particularly in cases with distribution shifts and rapidly changing models, such as evolving data streams. In this context, I co-organized the [TempXAI: Explainable AI for Time Series and Data Streams Tutorial-Workshop](https://sites.google.com/view/tempxai-workshop/home) at ECML PKDD 2024 and the [DynXAI: Explainable Artificial Intelligence
from Static to Dynamic Workshop](https://sites.google.com/view/dynxai-ecmlpkdd-2023) at ECML PKDD 2023.

I was part of the collaborative research centre [TRR 318 Constructing Explainability](https://trr318.uni-paderborn.de/en/).
